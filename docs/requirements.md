## flowaudit â€“ Transparent Invoice Auditing with LLMs (Seminar System)
**Version:** 1.0 (Seminar-Release)
**Primary Goal:** Didaktische Transparenz (Input â†’ Verarbeitung â†’ Output â†’ Feedback â†’ Lernen)
**Target Host:** ASUS NUC (64 GB RAM), Docker, optional GPU
**Frontend Languages:** Deutsch & Englisch (UI vollstÃ¤ndig zweisprachig)
**Rule Sets:** ğŸ‡©ğŸ‡ª DE (UStG Â§14), ğŸ‡ªğŸ‡º EU VAT, ğŸ‡¬ğŸ‡§ UK VAT
**LLM Providers:** Local (Ollama + trainable local model), External (OpenAI, Gemini)

---

## 0. Nicht-Ziele / Abgrenzung (wichtig fÃ¼r Seminar-Transparenz)

* Kein rechtsverbindlicher Steuerbescheid / keine automatische Entscheidung.
* Kein â€Prompt-Engineering UIâ€œ. Prompts bleiben serverseitig.
* Kein Speichern von Generator-Truth in DB (Truth nur als Textdatei im Exportordner).
* Kein automatisches â€Lernenâ€œ ohne menschliche Korrektur (Training nur aus bestÃ¤tigtem Feedback).

---

## 1. SystemÃ¼berblick â€“ Didaktik (was Teilnehmende verstehen sollen)

Teilnehmende mÃ¼ssen im System nachvollziehen kÃ¶nnen:

1. **Welche Anforderungen** gelten (Regelwerk & Merkmale).
2. **Wie PDFs maschinenlesbar werden** (Parser-Ausgabe).
3. **Was genau an die KI Ã¼bergeben wird** (Input-JSON).
4. **Welche Antwort kommt zurÃ¼ck** (Response-JSON).
5. **Wie Menschen Feedback geben** (Accept/Correct + Kommentar).
6. **Wie Training funktioniert** (lokale LLM: Datensatz â†’ Training â†’ Modellversion).
7. **Wie sich Leistung und QualitÃ¤t messen lassen** (Statistiken, Telemetrie, Lernkurven).
8. **Warum externe LLMs nicht â€lokal trainierbarâ€œ sind**, aber trotzdem vergleichbar (Laufzeiten/Erkennung/Fehlerquote).

---

## 2. Monorepo & Deploy (Docker)

### 2.1 Repository Layout

```
flowaudit/
â”œâ”€â”€ frontend/
â”œâ”€â”€ backend/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ runtime/                 # Ollama runtime container
â”‚   â””â”€â”€ trainer/                 # local training container (LoRA/QLoRA)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/                 # hochgeladene PDFs (runtime)
â”‚   â”œâ”€â”€ exports/                 # Generator output (PDF + truth)
â”‚   â”œâ”€â”€ previews/                # Template previews
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ datasets/            # exported JSONL datasets + manifests
â”‚   â”‚   â””â”€â”€ runs/                # training run artifacts + metrics
â”‚   â””â”€â”€ logs/                    # log files & request traces
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ docs/
    â”œâ”€â”€ REQUIREMENTS.md
    â””â”€â”€ CLAUDE.md
```

### 2.2 Docker Compose Services (minimum)

* `frontend` (React/Vue)
* `backend` (FastAPI)
* `db` (PostgreSQL empfohlen; SQLite optional fÃ¼r Demo-only)
* `ollama` (local inference)
* `trainer` (local fine-tuning jobs)
* optional: `monitor` (simple telemetry aggregator)

### 2.3 Healthchecks

* Backend: `/health`
* DB: basic connection
* Ollama: `/api/tags` erreichbar

---

## 3. Regelwerke / Rule Sets (Flag-select)

### 3.1 Startscreen: Flaggenwahl

* ğŸ‡©ğŸ‡ª â†’ Ruleset `DE_USTG_14` (DE UI default)
* ğŸ‡ªğŸ‡º â†’ Ruleset `EU_VAT` (EN UI default, optional DE UI)
* ğŸ‡¬ğŸ‡§ â†’ Ruleset `UK_VAT` (EN UI default)

**Wichtig:** Sprachwahl (DE/EN UI) ist **unabhÃ¤ngig** vom Ruleset.
Beispiel: UI Deutsch, Ruleset UK VAT (fÃ¼r deutsche Teilnehmende) ist mÃ¶glich.

### 3.2 Ruleset-Datenstruktur (versioniert, editierbar)

```json
{
  "ruleset_id": "DE_USTG_14",
  "ruleset_version": "1.0",
  "locale_default": "de",
  "display_name": {"de":"UStG Â§14", "en":"German VAT Act Â§14"},
  "legal_basis": {"de":"Â§ 14 Abs. 4 UStG", "en":"German VAT Act Â§14(4)"},
  "features": [
    {
      "id": "supplier_name_address",
      "label": {"de":"Name und Anschrift leistender Unternehmer", "en":"Supplier name and address"},
      "required": true,
      "severity": "critical",
      "explanation": {"de":"Pflichtangabe nach Â§ 14 Abs. 4 Nr. 1 UStG", "en":"Mandatory invoice field ..."},
      "examples": {
        "positive": ["Muster GmbH, MusterstraÃŸe 1, 12345 Musterstadt"],
        "negative": ["nur 'Muster GmbH' ohne Anschrift"]
      }
    }
  ]
}
```

### 3.3 Feature-Severity (fÃ¼r Seminar)

* `critical` (Fehlt â†’ hohes Risiko)
* `major`
* `minor`

Diese Severity wird fÃ¼r:

* Ergebnisampel
* Fehlerschwere im Generator
* Lernkurven nach Merkmal

---

## 4. Vorhaben / Project Context (fÃ¼r Zweck & ZeitprÃ¼fung)

### 4.1 Project Modell

```json
{
  "project_id": "PRJ_001",
  "title": "BaumaÃŸnahme Aschaffenburg",
  "description": "Umbau und Sanierung ...",
  "period_start": "2025-01-01",
  "period_end": "2025-12-31",
  "total_volume_eur": 1200000,
  "cost_categories": [
    {"code":"BAU", "label_de":"Bauleistungen", "label_en":"Construction works"},
    {"code":"PLAN", "label_de":"Planung", "label_en":"Planning"},
    {"code":"IT", "label_de":"IT-Infrastruktur", "label_en":"IT infrastructure"}
  ],
  "beneficiary": {
    "name": "Stadt Aschaffenburg",
    "address": "..."
  }
}
```

### 4.2 Hard Checks (ohne KI)

* `invoice_date` im Projektzeitraum? (ja/nein/unklar)
* `service_period` Ã¼berschneidet Projektzeitraum? (ja/nein/unklar)

Diese Flags werden:

* in der Ergebnisliste angezeigt
* in den KI-Input aufgenommen
* bei Konflikt mit KI-Aussage markiert

---

## 5. PDF Parser (Pflichtmodul, â€zerlegtâ€œ PDF)

### 5.1 Ziel

Parser erzeugt:

* Text (gesamt + je Seite)
* Zeilen (fÃ¼r Nachvollziehbarkeit)
* erkannte Felder (Datum, Zeitraum, BetrÃ¤ge wenn robust)
* Normalisierung von Datumsformaten

### 5.2 Parser Output Schema (persistiert)

```json
{
  "parser_version": "1.0",
  "file": {"name":"INV_001.pdf","sha256":"..."},
  "pages":[
    {"page":1,"text":"...","lines":["...","..."]}
  ],
  "extracted": {
    "invoice_number": {"value":"2025-001","confidence":0.62,"source":"regex"},
    "invoice_date": {"value":"2025-03-15","confidence":0.85,"source":"regex"},
    "service_period": {"from":"2025-01-01","to":"2025-12-31","confidence":0.71,"source":"nlp/regex"},
    "net_total": {"value": "1000.00", "currency":"EUR", "confidence":0.55},
    "vat_total": {"value": "190.00", "currency":"EUR", "confidence":0.55}
  }
}
```

### 5.3 Parser Tools

* Pflicht: `pdfplumber`
* optional: regex library, dateparser

### 5.4 Robustheit

* Wenn Felder nicht sicher extrahierbar sind â†’ `confidence` niedrig + `value` null.
* Der Parser darf niemals â€ratenâ€œ, sondern muss Unklarheit markieren.

---

## 6. KI Input/Output â€“ Transparenz ohne Prompt

### 6.1 KI-Input-JSON (Viewer-Reiter, exakt sichtbar)

```json
{
  "meta": {
    "run_id": "run_...",
    "ruleset_id": "DE_USTG_14",
    "ruleset_version": "1.0",
    "ui_locale": "de",
    "model_selected": "local:flowaudit-local-ft-v3"
  },
  "project": { ... },
  "requirements": { ... ruleset features ... },
  "parser_output": { ... },
  "hard_checks": {
    "invoice_date_in_project_period": "yes|no|unclear",
    "service_period_in_project_period": "yes|no|unclear"
  }
}
```

### 6.2 KI-Response-JSON (Viewer-Reiter, sichtbar)

```json
{
  "model": "flowaudit-local-ft-v3",
  "results": [
    {
      "feature_id": "vat_id_or_tax_number",
      "status": "ok|missing|unclear",
      "comment_de": "â€¦",
      "comment_en": "â€¦"
    }
  ],
  "overall_assessment": "ok|risk|needs_review",
  "summary_de": "â€¦",
  "summary_en": "â€¦"
}
```

**Hinweis:** Kommentare bilingual speichern, UI zeigt passend zur Sprache.

---

## 7. UI â€“ Kernworkflows

### 7.1 Modus A: Teilnehmer (Standard)

* Drag&Drop Upload (PDF-only)
* Belegliste mit Status
* Analyse starten
* Live-LogView + Spinner (Logo) + Prozent
* Ergebnisliste
* Detailansicht + Feedback

### 7.2 Modus B: Trainer (versteckt)

* Generator
* Ruleset-Editor (Merkmale hinzufÃ¼gen/Ã¤ndern/versionieren)
* Training Dashboard (datasets, runs, model versions)
* Evaluation & A/B Comparisons

**Versteckmechanismus:** Trainer-MenÃ¼ nicht prominent; z. B. in Footer-Klickfolge oder Settings-Schalter mit Passwort (nur lokal).

---

## 8. Ãœbersichtsliste & Detailansicht (Pflicht)

### 8.1 Ãœbersichtsliste Spalten (konfigurierbar)

* Datei
* Parser OK/Fehler
* Modell
* Overall Assessment Ampel
* Kritische Merkmale missing
* Hard-check Konflikte (Zeit)
* Laufzeit je Dokument
* Feedback-Status (offen/akzeptiert/korrigiert)

### 8.2 Detailansicht Tabs (Pflicht)

1. PDF Viewer
2. Parser JSON (syntax highlight)
3. KI Input JSON (syntax highlight + Tooltips)
4. KI Response JSON (syntax highlight + Tooltips)
5. Feedback (Accept / Correct / Comment)
6. LogView (chronologisch, filterbar)

### 8.3 JSON Viewer Anforderungen

* Syntax Highlight
* Copy Button
* Expand/Collapse (Tree view optional)
* Tooltip-ErklÃ¤rungen pro Feld (z. B. â€feature_id erklÃ¤rtâ€œ)

---

## 9. Feedback & Versionierung (Pflicht)

### 9.1 Feedback Actions

* **Accept** (Ergebnis ok)
* **Correct** (status je Feature Ã¤ndern + Kommentar)
* **Comment only**

### 9.2 Versionierung

FÃ¼r jede Rechnung:

* `analysis_version` beginnt bei 1
* jede Korrektur erhÃ¶ht Version

Speicherobjekt:

```json
{
  "invoice_id":"...",
  "analysis_version": 3,
  "model_used":"...",
  "human_feedback": {
    "action":"correct",
    "changes":[{"feature_id":"vat_id_or_tax_number","status":"missing"}],
    "comment":"..."
  }
}
```

### 9.3 Belegliste im â€DataGridâ€œ erst nach Feedback

**Pflichtanforderung:**
Eine â€Belegliste / extrahierte Felder-Tabelleâ€œ (DataGrid) wird **erst angezeigt**, nachdem:

* Feedback abgegeben wurde (Accept/Correct),
  damit im Seminar sichtbar ist: *â€PrÃ¼fer bestÃ¤tigt erst, dann wird die strukturierte Datenlage finalisiert.â€œ*

---

## 10. Generator (Trainer-only, versteckt)

### 10.1 Zweck

Erzeugt **realistisch aussehende** Dummy-Rechnungen (PDF), gemischt korrekt/fehlerhaft.

### 10.2 Anforderungen

* 5 Templates (stark unterschiedliche Layouts)
* Templates als Vorschau oberhalb (Preview images)
* Checkbox-Auswahl: welche Templates aktiv
* Einstellbar:

  * Anzahl Rechnungen
  * Fehlerquote global
  * Fehlerschwere (Anzahl Fehler pro fehlerhafte Rechnung)
  * Fehlerverteilung pro Merkmal (Feature-weighting)
  * Datumsformat-Varianten (single date, range, textual)
  * Sprache: DE/EN abhÃ¤ngig von Ruleset
* Keine â€Beispielâ€œ-Marker in sichtbaren Inhalten (damit KI nichts triviales lernt)
* Unterschiedliche BriefkÃ¶pfe, SchriftgrÃ¶ÃŸen, Positionen (Adresse links/rechts), Tabellenformat variiert.

### 10.3 Generator Output

Exportverzeichnis wird im UI gewÃ¤hlt (nur erlaubte Aliase, kein freier Pfad):

* PDFs nach `/data/exports/<batch>/pdf/`
* LÃ¶sungen nach `/data/exports/<batch>/truth/solutions.txt`
* ZusÃ¤tzlich: `manifest.json` (Templates, Settings, Hashes)

**Wichtig:** solutions.txt wird **nicht** in DB gespeichert.

---

## 11. LLM Provider & Settings UI

### 11.1 UnterstÃ¼tzte Provider

| Provider | ID | API-Basis | Modelle (Beispiele) |
|----------|----|-----------|--------------------|
| **Lokal (Ollama)** | `LOCAL_OLLAMA` | `http://ollama:11434` | llama3.1:8b, mistral:7b, qwen2:7b |
| **OpenAI** | `OPENAI` | `https://api.openai.com/v1` | gpt-4o, gpt-4o-mini, gpt-4-turbo |
| **Anthropic (Claude)** | `ANTHROPIC` | `https://api.anthropic.com/v1` | claude-sonnet-4-20250514, claude-3-5-haiku-20241022 |
| **Google (Gemini)** | `GEMINI` | `https://generativelanguage.googleapis.com` | gemini-1.5-pro, gemini-1.5-flash |

### 11.2 Settings-UI Anforderungen (Pflicht)

#### 11.2.1 Provider-Auswahl

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš™ï¸ Einstellungen / Settings                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”€â”€ LLM-Provider fÃ¼r Analyse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                  â”‚
â”‚  Aktiver Provider:                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ â—‹ Lokal (Ollama)           â† Standard, Daten bleiben lokal â”‚â”‚
â”‚  â”‚ â—‹ OpenAI (ChatGPT)         âš ï¸ Daten werden Ã¼bertragen      â”‚â”‚
â”‚  â”‚ â—‹ Anthropic (Claude)       âš ï¸ Daten werden Ã¼bertragen      â”‚â”‚
â”‚  â”‚ â—‹ Google (Gemini)          âš ï¸ Daten werden Ã¼bertragen      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚  â”€â”€ Lokales Modell (Ollama) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                  â”‚
â”‚  VerfÃ¼gbare Modelle:  [ llama3.1:8b-instruct-q4     â–¼ ]        â”‚
â”‚                       â—‹ llama3.1:8b-instruct-q4 (geladen)      â”‚
â”‚                       â—‹ mistral:7b                             â”‚
â”‚                       â—‹ qwen2:7b                               â”‚
â”‚                       â—‹ flowaudit-ft-v1 (fine-tuned)           â”‚
â”‚                                                                  â”‚
â”‚  [ Modell laden ]   [ Neues Modell herunterladen ]             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 11.2.2 API-Key-Konfiguration (pro Provider)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”€â”€ API-Keys â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                  â”‚
â”‚  OpenAI:                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ ********************************abcd    â”‚ âœ“ Gesetzt         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚  [ Ã„ndern ] [ Testen ] [ LÃ¶schen ]                             â”‚
â”‚                                                                  â”‚
â”‚  Anthropic (Claude):                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ sk-ant-************************1234    â”‚ âœ“ Gesetzt         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚  [ Ã„ndern ] [ Testen ] [ LÃ¶schen ]                             â”‚
â”‚                                                                  â”‚
â”‚  Google (Gemini):                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚                                         â”‚ âœ— Nicht gesetzt   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚  [ API-Key eingeben ]                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 11.2.3 Modell-Auswahl (pro Provider)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”€â”€ Modellauswahl â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                  â”‚
â”‚  OpenAI Modell:       [ gpt-4o-mini              â–¼ ]           â”‚
â”‚                       â—‹ gpt-4o (teuer, beste QualitÃ¤t)         â”‚
â”‚                       â—‹ gpt-4o-mini (gÃ¼nstig, schnell)         â”‚
â”‚                       â—‹ gpt-4-turbo                            â”‚
â”‚                                                                  â”‚
â”‚  Anthropic Modell:    [ claude-sonnet-4-20250514     â–¼ ]           â”‚
â”‚                       â—‹ claude-sonnet-4-20250514 (Balance)             â”‚
â”‚                       â—‹ claude-3-5-haiku (schnell, gÃ¼nstig)    â”‚
â”‚                                                                  â”‚
â”‚  Gemini Modell:       [ gemini-1.5-flash         â–¼ ]           â”‚
â”‚                       â—‹ gemini-1.5-pro (beste QualitÃ¤t)        â”‚
â”‚                       â—‹ gemini-1.5-flash (schnell)             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 11.2.4 Erweiterte Einstellungen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”€â”€ Erweiterte Einstellungen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                  â”‚
â”‚  Temperature:         [ 0.2        ] (0.0 - 1.5)               â”‚
â”‚  Max Tokens:          [ 2000       ] (100 - 8192)              â”‚
â”‚  Timeout (Sekunden):  [ 120        ] (30 - 300)                â”‚
â”‚  Parallele Anfragen:  [ 2          ] (1 - 5)                   â”‚
â”‚                                                                  â”‚
â”‚  â˜ Verbose Logging aktivieren                                  â”‚
â”‚  â˜‘ Bei Fehler automatisch wiederholen (3x)                     â”‚
â”‚                                                                  â”‚
â”‚  [ Einstellungen speichern ]   [ ZurÃ¼cksetzen ]                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 11.3 API-Key-Sicherheit

| Anforderung | Implementierung |
|-------------|-----------------|
| **Anzeige maskiert** | Nur letzte 4 Zeichen sichtbar: `sk-ant-************************1234` |
| **Speicherung verschlÃ¼sselt** | AES-256 oder Fernet, Key aus Umgebungsvariable |
| **Keine Logs** | API-Keys werden niemals in Logs geschrieben |
| **Testfunktion** | "Testen"-Button prÃ¼ft Verbindung ohne Key anzuzeigen |
| **LÃ¶schbar** | User kann API-Key jederzeit entfernen |

### 11.4 Provider Adapter (Backend)

Einheitliches Interface:

```python
class BaseLLMProvider(ABC):
    @abstractmethod
    async def analyze(self, payload: PreparePayload) -> LLMResponse:
        """FÃ¼hrt Analyse durch und gibt strukturierte Antwort zurÃ¼ck."""
        pass

    @abstractmethod
    async def test_connection(self) -> bool:
        """Testet ob Provider erreichbar und API-Key gÃ¼ltig ist."""
        pass

    @abstractmethod
    def get_available_models(self) -> list[ModelInfo]:
        """Gibt Liste verfÃ¼gbarer Modelle zurÃ¼ck."""
        pass
```

### 11.5 Datenschutz-Hinweise in UI

Bei Auswahl eines externen Providers:

```
âš ï¸ HINWEIS: Bei Verwendung von [OpenAI/Claude/Gemini] werden
Rechnungsdaten an externe Server Ã¼bertragen.

Ãœbertragene Daten:
â€¢ Extrahierter Text aus PDFs
â€¢ Projektkontext (anonymisiert)
â€¢ Regelwerk-Anforderungen

Die Daten werden gemÃ¤ÃŸ den Datenschutzrichtlinien des
jeweiligen Anbieters verarbeitet.

[ Verstanden, fortfahren ]   [ Abbrechen ]
```

---

## 12. Laufzeit-/Nutzungsstatistik (alle Modelle, Pflicht)

Pro Run:

* Gesamtzeit
* Zeit pro Dokument
* Anzahl Dokumente
* Anzahl Features geprÃ¼ft
* Anzahl Erkennungen (ok/missing/unclear counts)
* Fehlerquote (gegen menschliches Feedback, sobald vorhanden)

UI:

* Run Summary Box (oben)
* Export als CSV/JSON

---

## 13. Local LLM Telemetrie (zusÃ¤tzlich, Pflicht)

Nur bei local:

* Token Input/Output/Total
* CPU avg/peak
* RAM avg/peak
* optional GPU usage
* tokens/s (wenn verfÃ¼gbar)

Erhebung:

* tokens: aus provider response oder tokenizer
* CPU/RAM: `psutil`
* GPU: `nvidia-smi` (optional)

---

## 14. Training (lokale LLM) â€“ sichtbar & dokumentiert

### 14.1 Trainingsdaten entstehen nur aus Feedback

* Nur bestÃ¤tigte Korrekturen werden Trainingsbeispiele.

### 14.2 Dataset Export (JSONL)

Endpoint:

* `POST /api/training/export`
  Output:
* `/data/training/datasets/<dataset_id>/train.jsonl`
* `/data/training/datasets/<dataset_id>/val.jsonl`
* `/data/training/datasets/<dataset_id>/manifest.json` (counts, hashes, seed)

### 14.3 Training Run Orchestrierung

Endpoint:

* `POST /api/training/runs`
  Parameter:
* dataset_id, base_model, epochs, lr, lora_rank, seed

Artifacts:

* adapter files
* metrics.json (loss, eval)
* run logs

### 14.4 Modell Registry

Endpoint:

* `POST /api/models/register`
  List:
* `GET /api/models`

UI:

* Model Versions list (v1, v2, v3)
* â€œtrained on N examplesâ€ counter

---

## 15. Evaluation & Lernkurven (Pflicht)

### 15.1 Holdout/Eval Set

Es gibt einen festen Eval-Satz (nicht fÃ¼rs Training).
Daraus werden Metriken pro Modellversion berechnet.

### 15.2 Metriken

Pro Feature:

* Precision / Recall / F1 (ok/missing/unclear classification)
* Confusion counts

Global:

* Macro-F1
* Overall assessment accuracy
* Fehlerquote Ã¼ber Zeit

### 15.3 UI: Learning Dashboard

* Trainingsbeispiele count (gesamt, pro ruleset, pro Sprache)
* Training runs count
* Modellversionen + â€œtrained on â€¦â€
* Lernkurve (F1 Ã¼ber Versionen)
* Fehlerkurve (kritische Features separat)
* A/B Vergleich (Model A vs B vs C)

---

## 16. Vergleich externer vs lokaler Modelle (Seminarpflicht)

Auch externe Provider zeigen:

* Laufzeit
* Dokumentcount
* Featurecount
* Erkennungscounts (ok/missing/unclear)
* Fehlerquote bezogen auf Feedback (falls vorhanden)

Lokale Provider zusÃ¤tzlich:

* Tokens
* CPU/RAM/GPU
* Trainingsstand

---

## 17. Logging & LogView (Pflicht)

### 17.1 Was geloggt wird

* Upload event
* Parser start/end + duration
* Input JSON created (hash + size, optional full JSON in verbose)
* Provider call start/end + status
* Response received
* Persist events
* Training run events

### 17.2 LogView UI

* Filter (parser/provider/training)
* per Dokument
* per Run
* Export

---

## 18. Datenbank (Minimum Tables)

### 18.1 Tabellen

* `rulesets`
* `ruleset_versions`
* `projects`
* `invoices`
* `parser_outputs`
* `analysis_runs`
* `analysis_results`
* `feedback`
* `training_examples`
* `training_datasets`
* `training_runs`
* `model_registry`
* `model_metrics`

**Wichtig:** Keine Generator-truth in DB.

---

## 19. Sicherheit & Datenschutz (Seminarbetrieb)

* Uploads lokal
* keine offenen Ports nÃ¶tig (optional Cloudflare Tunnel)
* externe Provider: klare Kennzeichnung â€Data leaves deviceâ€œ
* API keys verschlÃ¼sselt/secret storage (mindestens env + masked UI)

---

## 20. Error Handling & Recovery (Pflicht)

### 20.1 Fehlerklassifikation

| Fehlerklasse | Beschreibung | Auswirkung |
|--------------|--------------|------------|
| `RECOVERABLE` | Kann automatisch wiederholt werden | Retry mit Backoff |
| `USER_CORRECTABLE` | Benutzer kann beheben | Fehlermeldung mit Anleitung |
| `SYSTEM_ERROR` | Systemfehler, Admin nÃ¶tig | Alert + Logging |
| `DATA_ERROR` | Fehlerhafte Eingabedaten | Dokument als ERROR markieren |

### 20.2 Fehlerszenarien und Reaktionen

#### 20.2.1 PDF-Parser-Fehler

| Fehler | Reaktion |
|--------|----------|
| PDF korrupt/unlesbar | Status `ERROR`, Meldung "PDF konnte nicht gelesen werden" |
| PDF passwortgeschÃ¼tzt | Status `ERROR`, Meldung "PasswortgeschÃ¼tzte PDFs nicht unterstÃ¼tzt" |
| Kein Text extrahierbar (Bild-PDF) | Status `PARSED` mit Warning, OCR-Hinweis in UI |
| Parser-Timeout (>30s) | Retry 1x, dann Status `ERROR` |
| SpeicherÃ¼berlauf | Task abbrechen, Status `ERROR`, Alert an Admin |

#### 20.2.2 LLM-Provider-Fehler

| Fehler | Reaktion |
|--------|----------|
| Connection Timeout | 3 Retries mit exponential backoff (2s, 4s, 8s) |
| Rate Limit (429) | Warten + Retry nach Header-Info oder 60s |
| Invalid API Key | Status `ERROR`, Settings-PrÃ¼fung anfordern |
| Model not found | Fallback auf Standard-Modell, Warning |
| Context too long | Text kÃ¼rzen, Retry |
| Invalid JSON Response | 2 Retries, dann manuelle Struktur-Extraktion |
| Provider nicht erreichbar | Fallback auf alternativen Provider (wenn konfiguriert) |

#### 20.2.3 Datenbank-Fehler

| Fehler | Reaktion |
|--------|----------|
| Connection lost | Retry mit Connection Pool |
| Constraint violation | Rollback, aussagekrÃ¤ftige Fehlermeldung |
| Disk full | Alert an Admin, keine neuen Uploads |
| Migration failed | Rollback, System bleibt auf alter Version |

#### 20.2.4 Dateisystem-Fehler

| Fehler | Reaktion |
|--------|----------|
| Upload-Verzeichnis nicht beschreibbar | Alert, Upload-Endpoint deaktivieren |
| PDF nicht gefunden | Status `ERROR`, KonsistenzprÃ¼fung triggern |
| Export-Fehler | Retry 1x, dann Error an User |

### 20.3 Retry-Strategien

```python
RETRY_CONFIG = {
    "pdf_parse": {
        "max_retries": 1,
        "backoff": "none",
        "timeout_seconds": 30
    },
    "llm_call": {
        "max_retries": 3,
        "backoff": "exponential",
        "base_delay_seconds": 2,
        "max_delay_seconds": 30,
        "timeout_seconds": 120
    },
    "db_operation": {
        "max_retries": 3,
        "backoff": "linear",
        "delay_seconds": 1,
        "timeout_seconds": 10
    },
    "external_api": {
        "max_retries": 3,
        "backoff": "exponential",
        "base_delay_seconds": 5,
        "max_delay_seconds": 60,
        "respect_rate_limit_headers": True
    }
}
```

### 20.4 Benutzer-Fehlermeldungen (zweisprachig)

| Fehler-Code | Meldung (DE) | Meldung (EN) |
|-------------|--------------|--------------|
| `PDF_CORRUPT` | "Die PDF-Datei ist beschÃ¤digt oder nicht lesbar." | "The PDF file is corrupted or unreadable." |
| `PDF_PASSWORD` | "PasswortgeschÃ¼tzte PDFs werden nicht unterstÃ¼tzt." | "Password-protected PDFs are not supported." |
| `PDF_NO_TEXT` | "Kein Text im PDF gefunden. MÃ¶glicherweise ein Bild-PDF." | "No text found in PDF. It may be an image-based PDF." |
| `LLM_UNAVAILABLE` | "Der KI-Dienst ist vorÃ¼bergehend nicht erreichbar." | "The AI service is temporarily unavailable." |
| `LLM_TIMEOUT` | "Die Analyse hat zu lange gedauert. Bitte erneut versuchen." | "Analysis took too long. Please try again." |
| `UPLOAD_FAILED` | "Upload fehlgeschlagen. Bitte erneut versuchen." | "Upload failed. Please try again." |
| `EXPORT_FAILED` | "Export konnte nicht erstellt werden." | "Export could not be created." |

### 20.5 Logging-Anforderungen

**Jeder Fehler muss enthalten:**
```json
{
  "timestamp": "2025-12-15T12:00:00Z",
  "level": "ERROR",
  "error_code": "LLM_TIMEOUT",
  "error_class": "RECOVERABLE",
  "service": "worker",
  "task_id": "task_123",
  "document_id": "doc_456",
  "project_id": "prj_789",
  "message": "LLM call timed out after 120s",
  "details": {
    "provider": "LOCAL_OLLAMA",
    "model": "llama3.1:8b",
    "retry_count": 3,
    "last_error": "Connection timed out"
  },
  "stack_trace": "..."
}
```

### 20.6 Health-Check-Integration

```python
# Automatische Fehlererkennung Ã¼ber Health-Checks
HEALTH_CHECK_CONFIG = {
    "db": {
        "interval_seconds": 30,
        "timeout_seconds": 5,
        "unhealthy_threshold": 3
    },
    "ollama": {
        "interval_seconds": 60,
        "timeout_seconds": 10,
        "unhealthy_threshold": 2
    },
    "chroma": {
        "interval_seconds": 60,
        "timeout_seconds": 5,
        "unhealthy_threshold": 3
    },
    "redis": {
        "interval_seconds": 30,
        "timeout_seconds": 5,
        "unhealthy_threshold": 2
    }
}
```

### 20.7 Graceful Degradation

| Komponente ausfallend | Degradiertes Verhalten |
|-----------------------|------------------------|
| Ollama | Nur externe Provider nutzbar, UI-Hinweis |
| ChromaDB | RAG deaktiviert, Analyse ohne Few-Shot |
| Redis | Synchrone Verarbeitung statt Queue |
| PostgreSQL | System nicht nutzbar, Maintenance-Seite |

---

## 21. Abnahmekriterien (Definition of Done)

Das System ist nur â€fertigâ€œ, wenn:

1. Parser funktioniert robust fÃ¼r 5 Generator-Templates
2. UI zeigt: PDF + Parser JSON + Input JSON + Response JSON
3. Prompt ist nirgendwo sichtbar
4. Generator erzeugt PDFs + solutions.txt im gewÃ¤hlten Exportordner
5. solutions.txt wird NICHT in DB gespeichert
6. Feedback erzeugt Versionen
7. Belegliste/DataGrid erscheint erst nach Feedback
8. Statistiken fÃ¼r externe & lokale Modelle vorhanden
9. Lokale Telemetrie (tokens/cpu/ram) sichtbar
10. Training lÃ¤uft lokal, neue Modellversion registrierbar
11. Lern-Dashboard zeigt Kurven + ZÃ¤hler + Fehlerquoten
12. A/B Vergleich funktioniert

---

## 21. Minimaler MVP-Plan (fÃ¼r Claude Code Umsetzung)

**MVP 1:** Parser + Viewer + External Provider + Stats
**MVP 2:** Generator + Template Previews + Hidden Trainer Menu
**MVP 3:** Local Ollama + Telemetry + Settings
**MVP 4:** Feedback Versionierung + DataGrid-after-feedback
**MVP 5:** Training pipeline + Model registry + Evaluation + Learning dashboard


# flowaudit â€“ Beleganalyse (UStG + Zuwendungszweck) mit lokaler KI
**Konzept- & Setup-Guide (GitHub-Repo-Startpunkt)**  
Stand: 12.12.2025

Dieses Repository beschreibt ein System, mit dem Nutzer **ohne Prompt-Eingabe** PDFâ€‘Belege hochladen (oder aus einem Schulungsset auswÃ¤hlen) und eine **Ergebnisliste** erhalten. Die KI lÃ¤uft **unsichtbar im Backend** (lokal Ã¼ber Ollama oder alternativ Ã¼ber Cloudâ€‘API).

Das System unterstÃ¼tzt zwei Modi:
- **Training (Anlernen):** Belege hochladen/auswÃ¤hlen, Goldstandard pro Modul erfassen (Labels + BegrÃ¼ndung).
- **PrÃ¼fen (Module 1â€“3):** Vorhabenprofil erfassen/auswÃ¤hlen, Belege hochladen, Analyse starten, Ergebnisse ansehen, Feedback speichern.

---

## 1. Ziele und Grundprinzipien

### 1.1 Nutzerinteraktion (keine Prompts)
- Frontend bietet **nur**:
  - Dateiâ€‘Upload (PDF; optional Batch)
  - Auswahl aus Schulungsbelegen
  - Startâ€‘Button â€Analyseâ€œ
  - Ergebnisliste + Detailansicht + Feedback
- **Kein** Freitextâ€‘Promptfeld. Prompts sind **fest im Backend versioniert**.

### 1.2 Fachliche Module
- **Modul 1 â€“ UStGâ€‘Rechnungspflichtangaben**  
  Fokus auf formale Anforderungen (Vorsteuerâ€‘Relevanz als PrÃ¼fhilfe). Typische Pflichtangaben ergeben sich aus **Â§ 14 Abs. 4 UStG**, SonderfÃ¤lle aus **Â§ 14a UStG**, Vorsteuerabzug aus **Â§ 15 Abs. 1 UStG**.
- **Modul 2 â€“ Vorhabenzusammenhang / Zuwendungszweck**  
  PrÃ¼fung, ob der Beleg sachlich/zeitlich/organisatorisch plausibel zum Vorhaben passt (Zweckbindung).
- **Modul 3 â€“ Risiko / Vergabe / weitere PrÃ¼fregeln (optional erweiterbar)**  
  Z.â€¯B. vergaberechtliche Indikatoren, PlausibilitÃ¤ten, typische Fehlerbilder, Checklistenlogik.

### 1.3 â€Wiedererkennungâ€œ der 50 Schulungsbelege
Ein LLM â€merktâ€œ Belege nicht wie ein Speicher. FÃ¼r **sofortige Wiedererkennung** nutzen wir im Backend:
- **Fingerprint (SHAâ€‘256)** Ã¼ber PDFâ€‘Bytes oder normalisierten Extraktâ€‘Text
- Lookup in DB â†’ wenn bekannt: Ergebnis **aus DB** statt Inferenz

---

## 2. Architektur

### 2.1 Komponenten (Dockerâ€‘Stack)
- **frontend** (React oder Vue) â€“ Upload, Trainingâ€‘Formulare, Ergebnisliste, Detail, Feedback
- **api** (FastAPI) â€“ Uploadâ€‘Endpoints, Projektprofile, Jobâ€‘Start, Ergebnisâ€‘API
- **worker** (Celery/RQ/Arq) â€“ Batchâ€‘Analyse, Parallelisierung, robuste Jobs
- **db** (PostgreSQL) â€“ Belege, Projekte, Ergebnisse, Trainingsdaten, Feedback, Promptâ€‘Versionen
- **ollama** (lokales LLM) â€“ Inferenz Ã¼ber HTTP (z.â€¯B. Llama/Qwen/Mistral)
- **traefik** (optional) â€“ Reverse Proxy, HTTPS (oder Cloudflare Tunnel)
- **minio** (optional) â€“ Objektâ€‘Storage fÃ¼r PDFs (statt Dateisystem)
- **pgadmin** (optional) â€“ DBâ€‘UI

### 2.2 Datenfluss (PrÃ¼fmodus)
1. Upload PDF(s) â†’ `api` speichert Datei + extrahiert Text
2. Fingerprint berechnen â†’ bekannte Belege?  
   - Ja â†’ Ergebnis aus DB laden  
   - Nein â†’ Job an `worker` geben
3. Worker:
   - Promptâ€‘Version laden (fest versioniert)
   - Modul 1â€“3 ausfÃ¼hren (lokales LLM oder Cloud)
   - JSON validieren â†’ DB schreiben
4. Frontend pollt Status â†’ Ergebnisliste â†’ Detailansicht â†’ Feedback speichern

### 2.3 Datenfluss (Trainingsmodus)
1. Upload/Select Beleg â†’ extrahierter Text sichtbar (optional)
2. Goldstandard pro Modul erfassen (ok/missing/unclear etc.)
3. Speicherung als **Training Example** (Goldstandard)  
4. Optional: â€KIâ€‘Vorschlag holenâ€œ â†’ dann manuell korrigieren â†’ als Goldstandard speichern

---

## 3. Repoâ€‘Struktur (Vorschlag)

```text
flowaudit-invoice-ai/
â”œâ”€ README.md
â”œâ”€ docs/
â”‚  â”œâ”€ 01_architektur.md
â”‚  â”œâ”€ 02_datenmodell.md
â”‚  â”œâ”€ 03_prompts.md
â”‚  â”œâ”€ 04_security.md
â”‚  â”œâ”€ 05_training_workflow.md
â”‚  â””â”€ 06_codex_workflow.md
â”œâ”€ deploy/
â”‚  â”œâ”€ docker-compose.yml
â”‚  â”œâ”€ docker-compose.override.example.yml
â”‚  â”œâ”€ traefik/
â”‚  â”‚  â”œâ”€ traefik.yml
â”‚  â”‚  â””â”€ dynamic.yml
â”‚  â””â”€ cloudflared/
â”‚     â””â”€ config.yml
â”œâ”€ backend/
â”‚  â”œâ”€ Dockerfile
â”‚  â”œâ”€ pyproject.toml
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ main.py
â”‚  â”‚  â”œâ”€ config.py
â”‚  â”‚  â”œâ”€ api/
â”‚  â”‚  â”‚  â”œâ”€ routes_invoices.py
â”‚  â”‚  â”‚  â”œâ”€ routes_projects.py
â”‚  â”‚  â”‚  â”œâ”€ routes_training.py
â”‚  â”‚  â”‚  â””â”€ routes_results.py
â”‚  â”‚  â”œâ”€ services/
â”‚  â”‚  â”‚  â”œâ”€ pdf_extract.py
â”‚  â”‚  â”‚  â”œâ”€ fingerprint.py
â”‚  â”‚  â”‚  â”œâ”€ llm_client_ollama.py
â”‚  â”‚  â”‚  â”œâ”€ llm_prompts.py
â”‚  â”‚  â”‚  â”œâ”€ validators.py
â”‚  â”‚  â”‚  â””â”€ scoring.py
â”‚  â”‚  â”œâ”€ db/
â”‚  â”‚  â”‚  â”œâ”€ session.py
â”‚  â”‚  â”‚  â”œâ”€ models.py
â”‚  â”‚  â”‚  â””â”€ migrations/
â”‚  â”‚  â””â”€ worker/
â”‚  â”‚     â”œâ”€ tasks.py
â”‚  â”‚     â””â”€ queue.py
â”‚  â””â”€ tests/
â”œâ”€ frontend/
â”‚  â”œâ”€ Dockerfile
â”‚  â”œâ”€ package.json
â”‚  â””â”€ src/
â”‚     â”œâ”€ pages/
â”‚     â”‚  â”œâ”€ Training.tsx
â”‚     â”‚  â”œâ”€ Check.tsx
â”‚     â”‚  â””â”€ Projects.tsx
â”‚     â”œâ”€ components/
â”‚     â”‚  â”œâ”€ UploadDropzone.tsx
â”‚     â”‚  â”œâ”€ ResultsTable.tsx
â”‚     â”‚  â”œâ”€ InvoiceDetail.tsx
â”‚     â”‚  â””â”€ ModuleTabs.tsx
â”‚     â””â”€ lib/api.ts
â””â”€ data/
   â”œâ”€ training_invoices/   (nur fÃ¼r Demo/Schulung; optional .gitignore)
   â””â”€ seed/
      â”œâ”€ projects.json
      â””â”€ invoices_manifest.json
```

---

## 4. Datenmodell (Minimalâ€‘Variante)

### 4.1 Tabellen
**invoices**
- `id` (PK)
- `fingerprint` (unique, SHAâ€‘256)
- `file_name`
- `storage_path` (oder minio key)
- `text_extracted`
- `created_at`

**projects**
- `id` (PK)
- `code` (unique)
- `title`
- `description`
- `funding_purpose`
- `period_start`, `period_end`
- `beneficiary_name`
- `eligible_cost_categories` (JSON)
- `ineligible_cost_examples` (JSON)
- `created_at`

**prompt_versions**
- `id` (PK)
- `module` (1/2/3)
- `version` (z.â€¯B. `m1_v1.2`)
- `prompt_template` (Text)
- `schema_json` (JSONâ€‘Schema)
- `created_at`

**ai_results**
- `id` (PK)
- `invoice_id` (FK)
- `project_id` (FK, nullable)
- `module` (1/2/3)
- `model_name`
- `prompt_version_id` (FK)
- `result_json`
- `status` (queued/running/done/failed)
- `created_at`

**training_examples**
- `id` (PK)
- `invoice_id` (FK)
- `project_id` (FK, nullable)
- `module` (1/2/3)
- `label_json` (Goldstandard)
- `source` (manual/corrected_from_ai)
- `created_at`

**feedback**
- `id` (PK)
- `ai_result_id` (FK)
- `module`
- `rating` (correct/partial/wrong)
- `correction_json`
- `comment`
- `created_at`

---

## 5. Ergebnisâ€‘Schemas (Beispiel)

### 5.1 Modul 1 â€“ UStG (Beispielâ€‘JSON)
```json
{
  "invoice_number": "2025-001",
  "issue_date": "2025-10-15",
  "supplier_name": "Muster GmbH",
  "customer_name": "BegÃ¼nstigter e.V.",
  "net_amount_total": "1000.00",
  "vat_amount_total": "190.00",
  "checks": [
    {
      "field": "supplier_name_and_address",
      "required_by": "Â§ 14 Abs. 4 Nr. 1 UStG",
      "status": "ok",
      "comment": "Name und Anschrift des leistenden Unternehmers sind angegeben."
    }
  ],
  "overall_assessment": "likely_valid",
  "overall_comment": "Formale Pflichtangaben Ã¼berwiegend vorhanden; keine offensichtlichen AusschlussgrÃ¼nde erkennbar."
}
```

### 5.2 Modul 2 â€“ Vorhabenzusammenhang (Beispielâ€‘JSON)
```json
{
  "project_relation": {
    "relation_level": "yes",
    "score": 0.86,
    "mapped_cost_category": "Baukosten",
    "time_plausible": true,
    "beneficiary_plausible": true,
    "reasons": [
      "Leistungsbeschreibung bezieht sich auf Umbau/Installation im Projektstandort.",
      "Rechnungsdatum liegt innerhalb des FÃ¶rderzeitraums.",
      "Kostenart ist im Projektprofil als fÃ¶rderfÃ¤hig vorgesehen."
    ]
  }
}
```

### 5.3 Modul 3 â€“ Risikoindikatoren (Beispielâ€‘JSON)
```json
{
  "risk": {
    "risk_level": "medium",
    "signals": [
      "Leistungszeitpunkt nicht eindeutig angegeben",
      "Positionen sehr allgemein beschrieben"
    ],
    "recommendations": [
      "Leistungsnachweis/Abnahmeprotokoll anfordern",
      "Projektzuordnung Ã¼ber KostentrÃ¤ger prÃ¼fen"
    ]
  }
}
```

---

## 6. Setup auf dem NUC (Ubuntu Server)

### 6.1 Basisâ€‘Installation
Empfohlen: Ubuntu Server LTS, SSH aktiviert.

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y ca-certificates curl gnupg git ufw
```

### 6.2 Docker installieren
```bash
curl -fsSL https://get.docker.com | sudo sh
sudo usermod -aG docker $USER
newgrp docker
```

### 6.3 NVIDIA (optional, fÃ¼r GPUâ€‘LLM)
Wenn GPUâ€‘Inferenz genutzt wird: NVIDIA Treiber + Container Toolkit.
(Die konkrete Version hÃ¤ngt vom System ab; anschlieÃŸend Test mit `nvidia-smi`.)

```bash
# (Beispiel) Toolkit installieren, dann:
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

### 6.4 Repo clonen und starten
```bash
git clone https://github.com/<dein-user>/flowaudit-invoice-ai.git
cd flowaudit-invoice-ai/deploy
cp .env.example .env
docker compose up -d --build
```

---

## 7. Docker Compose (Minimalâ€‘Beispiel)

> Datei: `deploy/docker-compose.yml` (Platzhalter â€“ im Repo ausformulieren)

```yaml
services:
  db:
    image: postgres:16
    environment:
      POSTGRES_USER: flowaudit
      POSTGRES_PASSWORD: flowaudit
      POSTGRES_DB: flowaudit
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  ollama:
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"

  api:
    build: ../backend
    environment:
      DATABASE_URL: postgresql+psycopg://flowaudit:flowaudit@db:5432/flowaudit
      OLLAMA_HOST: http://ollama:11434
      STORAGE_PATH: /data/invoices
    volumes:
      - ../data:/data
    ports:
      - "9100:8000"
    depends_on:
      - db
      - ollama

  worker:
    build: ../backend
    command: ["python", "-m", "app.worker.queue"]
    environment:
      DATABASE_URL: postgresql+psycopg://flowaudit:flowaudit@db:5432/flowaudit
      OLLAMA_HOST: http://ollama:11434
      STORAGE_PATH: /data/invoices
    volumes:
      - ../data:/data
    depends_on:
      - db
      - ollama

  frontend:
    build: ../frontend
    ports:
      - "3000:80"
    depends_on:
      - api

volumes:
  pgdata:
  ollama_data:
```

---

## 8. Sicherheitskonzept (Kurz)

### 8.1 Zugriff
- Idealfall: **Cloudflare Tunnel + Access** (kein Portâ€‘Forwarding)
- Alternativ: Reverse Proxy (Traefik) + HTTPS + Basic Auth/SSO
- Keine Ã¶ffentlichen DBâ€‘Ports im Internet

### 8.2 Daten
- PDFs und Extraktâ€‘Texte enthalten ggf. personenbezogene Daten
- Speicherung:
  - Dateisystem in Volume **oder** S3â€‘kompatibel (MinIO)
  - DB enthÃ¤lt Referenz + Ergebnisse + Hash
- Logging: keine Volltexte in Logs

### 8.3 Rollen
- Admin: Projekte/Prompts/Seeds
- Trainer: Trainingslabels pflegen
- Nutzer: Upload/PrÃ¼fen/Feedback

---

## 9. Schulungsmodus (die 50 Belege)

### 9.1 Seedâ€‘Belege vorbereiten
- Lege Schulungsâ€‘PDFs ab: `data/training_invoices/`
- Erstelle Manifest: `data/seed/invoices_manifest.json` (Dateiname, Code, Beschreibung)

### 9.2 Seedâ€‘Projekte vorbereiten
- `data/seed/projects.json` enthÃ¤lt 1â€“3 Projektprofile (Titel, Zweck, Zeitraum, Kostenarten)

### 9.3 ErstbefÃ¼llung
Ein Script `backend/app/db/seed.py`:
- liest Projekte/Manifest
- importiert PDFs (Fingerprint + Text)
- legt Trainingsbeispiele an (optional leer)
- optional: erzeugt KIâ€‘VorschlÃ¤ge und speichert sie als â€draftâ€œ

---

## 10. Implementierungsâ€‘Schritte (Roadmap)

### Schritt 1 â€“ Skeleton
- Docker Compose lauffÃ¤hig (db, api, frontend, ollama)
- Healthâ€‘Endpoints + Versioning

### Schritt 2 â€“ Upload + Extraktion
- `POST /api/invoices/upload`
- PDF speichern
- Text extrahieren (`pdfplumber` / `pypdf`)
- Fingerprint bilden

### Schritt 3 â€“ Datenmodell + Migration
- SQLAlchemy Models
- Alembic Migration

### Schritt 4 â€“ Analyseâ€‘Jobs
- `POST /api/run/analyze` startet Jobs (Batch)
- Worker fÃ¼hrt Module 1â€“3 aus
- Statusâ€‘Polling + Ergebnisâ€‘API

### Schritt 5 â€“ Trainingsseite
- Goldstandardâ€‘Formulare + Speicherung
- optional: KIâ€‘VorbefÃ¼llung

### Schritt 6 â€“ Feedbackâ€‘Loop
- Detailansicht + Feedback speichern
- Export: `training_examples` + `feedback` â†’ JSONL

### Schritt 7 â€“ Retrieval / Fewâ€‘Shot (optional)
- Ã„hnliche Trainingsbelege suchen (Embedding oder simpler TFâ€‘IDF)
- 1â€“3 Beispiele in Prompt einbetten, um Konsistenz zu erhÃ¶hen

### Schritt 8 â€“ Fineâ€‘Tuning (optional)
- Export JSONL
- Modell feinâ€‘tunen (lokal via LoRA oder extern)
- Modell in Ollama als neues Modell registrieren
- Konfiguration umstellen (`MODEL_NAME=jan-ustg-v1`)

---

## 11. Codexâ€‘Workflow (damit du das Repo â€programmieren lÃ¤sstâ€œ)

### 11.1 Arbeitsweise
- Erzeuge pro Feature ein **Issue** im Repo
- Lass Codex jeweils **nur** einen klaren Scope umsetzen
- Verlange:
  - keine Ã„nderungen auÃŸerhalb des Scope
  - Tests/Runâ€‘Commands
  - kurze BegrÃ¼ndung der Architekturentscheidung

### 11.2 Beispielâ€‘Prompts an Codex (Copy/Paste)

**Issue 1: Datenmodell + Alembic**
> Implementiere SQLAlchemyâ€‘Modelle und Alembicâ€‘Migrationen gemÃ¤ÃŸ docs/02_datenmodell.md.  
> Erzeuge Tabellen: invoices, projects, prompt_versions, ai_results, training_examples, feedback.  
> Nutze klare Constraints (unique fingerprint, FKâ€‘Beziehungen).  
> Schreibe auÃŸerdem ein Seedâ€‘Script fÃ¼r projects.json.

**Issue 2: Uploadâ€‘Endpoint**
> Implementiere `POST /api/invoices/upload` (multipart PDF).  
> Speichere Datei in STORAGE_PATH, extrahiere Text, berechne SHAâ€‘256 Fingerprint.  
> Lege invoiceâ€‘Datensatz an oder reuse bei bekanntem Fingerprint.  
> Gib JSON mit invoice_id und fingerprint zurÃ¼ck.

**Issue 3: Modulâ€‘Runner**
> Implementiere Workerâ€‘Task `analyze_invoice(invoice_id, project_id)` mit Modulen 1â€“3.  
> Prompts aus prompt_versions laden (Versioning).  
> LLM via Ollamaâ€‘HTTP aufrufen; Output als JSON validieren; Ergebnis in ai_results schreiben.

---

## 12. Betrieb, Updates, Backups

### 12.1 Updates
```bash
git pull
docker compose up -d --build
```

### 12.2 DBâ€‘Backup (Beispiel)
```bash
docker exec -t deploy-db-1 pg_dump -U flowaudit flowaudit > backup_flowaudit.sql
```

### 12.3 Datenâ€‘Backup zu QNAP (Beispiel rsync)
```bash
rsync -avz ./data/ user@qnap:/Backups/flowaudit/data/
```

